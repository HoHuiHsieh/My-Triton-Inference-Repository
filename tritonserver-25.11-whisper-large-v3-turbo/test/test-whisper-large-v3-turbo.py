#!/usr/bin/env python
"""
Test script for Whisper-Large-V3-Turbo model on Triton Inference Server.
Tests automatic speech recognition.
"""
import sys
import numpy as np
import tritonclient.grpc as grpcclient
from datasets import load_dataset


def test_audio_transcription(triton_client, model_name, audio_sample):
    """Test audio transcription."""
    print("\n" + "="*80)
    print("TEST: Audio Transcription")
    print("="*80)
    
    # Load audio bytes
    # The audio sample is a dict with 'array' and 'sampling_rate'
    audio_array = audio_sample["array"]
    sampling_rate = audio_sample["sampling_rate"]
    
    print(f"Audio array shape: {audio_array.shape}")
    print(f"Sampling rate: {sampling_rate}")
    
    # Convert audio array to bytes format that Whisper can process
    # We need to pass the audio data in a format the pipeline can handle
    # The pipeline expects either a file path, raw bytes, or a dict with 'array' and 'sampling_rate'
    import io
    import soundfile as sf
    
    # Convert numpy array to WAV bytes
    audio_bytes_io = io.BytesIO()
    sf.write(audio_bytes_io, audio_array, sampling_rate, format='WAV')
    audio_bytes = audio_bytes_io.getvalue()
    
    print(f"Audio bytes size: {len(audio_bytes)} bytes")
    
    # Prepare input - input_audio has dims [1]
    input_audio = grpcclient.InferInput("input_audio", [1], "BYTES")
    input_audio_data = np.array([audio_bytes], dtype=object)
    input_audio.set_data_from_numpy(input_audio_data)
    
    # Prepare output
    output = grpcclient.InferRequestedOutput("output_text")
    
    # Perform inference
    print("Sending audio to Triton server...")
    results = triton_client.infer(
        model_name=model_name,
        inputs=[input_audio],
        outputs=[output]
    )
    
    # Get transcription
    output_text = results.as_numpy("output_text")
    transcription = output_text[0].decode('utf-8') if isinstance(output_text[0], bytes) else str(output_text[0])
    
    print(f"\n{'='*80}")
    print("TRANSCRIPTION:")
    print(f"{'='*80}")
    print(transcription)
    print(f"{'='*80}")
    
    assert len(transcription) > 0, "Transcription should not be empty"
    print("‚úì Audio transcription test PASSED")
    
    return transcription


def test_with_synthetic_audio(triton_client, model_name):
    """Test with a synthetic audio sample (simple sine wave)."""
    print("\n" + "="*80)
    print("Generating synthetic audio sample...")
    print("="*80)
    
    try:
        # Generate a simple sine wave as a test audio
        # This won't produce meaningful transcription but tests the pipeline
        duration = 3  # seconds
        sampling_rate = 16000
        frequency = 440  # A4 note
        
        t = np.linspace(0, duration, int(sampling_rate * duration))
        audio_array = np.sin(2 * np.pi * frequency * t).astype(np.float32)
        
        audio_sample = {
            "array": audio_array,
            "sampling_rate": sampling_rate
        }
        
        print(f"Generated {duration}s sine wave at {frequency}Hz")
        print("Note: This is a test signal - transcription will be empty or noise-related")
        
        transcription = test_audio_transcription(triton_client, model_name, audio_sample)
        
        print("‚úì Synthetic audio test completed (validates pipeline only)")
        return transcription
    except Exception as e:
        print(f"‚ö† Warning: Could not generate synthetic audio: {e}")
        return None


def test_with_librispeech_sample(triton_client, model_name):
    """Test with a sample from LibriSpeech dataset."""
    print("\n" + "="*80)
    print("Loading LibriSpeech sample...")
    print("="*80)
    
    try:
        dataset = load_dataset("distil-whisper/librispeech_long", "clean", split="validation")
        sample = dataset[0]["audio"]
        
        print(f"Loaded sample from LibriSpeech")
        print(f"Expected text: {dataset[0].get('text', 'N/A')[:100]}...")
        
        transcription = test_audio_transcription(triton_client, model_name, sample)
        
        return transcription
    except Exception as e:
        print(f"‚ö† Warning: Could not load LibriSpeech dataset: {str(e)[:200]}...")
        print("Skipping LibriSpeech test")
        return None


def test_with_local_audio(triton_client, model_name, audio_file_path):
    """Test with a local audio file."""
    print("\n" + "="*80)
    print(f"TEST: Local Audio File - {audio_file_path}")
    print("="*80)
    
    try:
        import soundfile as sf
        
        # Load audio file
        audio_array, sampling_rate = sf.read(audio_file_path)
        print("******************************************\n", audio_array)
        audio_sample = {
            "array": audio_array,
            "sampling_rate": sampling_rate
        }
        
        transcription = test_audio_transcription(triton_client, model_name, audio_sample)
        
        return transcription
    except FileNotFoundError:
        print(f"‚ö† Warning: Audio file not found: {audio_file_path}")
        print("Skipping local audio test")
        return None
    except Exception as e:
        print(f"‚ö† Warning: Could not load audio file: {e}")
        print("Skipping local audio test")
        return None


def main():
    """Main test function."""
    print("="*80)
    print("Whisper-Large-V3-Turbo Triton Inference Server Test")
    print("="*80)
    
    # Check for required dependencies
    try:
        import soundfile
        print("‚úì soundfile library available")
    except ImportError:
        print("‚úó soundfile library not found. Install with: pip install soundfile")
        sys.exit(1)
    
    # Create Triton client
    try:
        triton_client = grpcclient.InferenceServerClient(
            url="0.0.0.0:8001",
            verbose=False,
            ssl=False
        )
        print("‚úì Successfully connected to Triton Server at 0.0.0.0:8001")
    except Exception as e:
        print(f"‚úó Failed to create Triton client: {str(e)}")
        sys.exit(1)
    
    model_name = "whisper-large-v3-turbo"
    
    # Check if model is ready
    try:
        if triton_client.is_model_ready(model_name):
            print(f"‚úì Model '{model_name}' is ready")
        else:
            print(f"‚úó Model '{model_name}' is not ready")
            sys.exit(1)
    except Exception as e:
        print(f"‚úó Error checking model status: {str(e)}")
        sys.exit(1)
    
    try:
        # Test 1: Local audio file (if provided via command line)
        if len(sys.argv) > 1:
            audio_file_path = sys.argv[1]
            local_result = test_with_local_audio(triton_client, model_name, audio_file_path)
        else:
            # Test 2: Try LibriSpeech dataset sample
            librispeech_result = test_with_librispeech_sample(triton_client, model_name)
            
            # Test 3: Fallback to synthetic audio if dataset failed
            if librispeech_result is None:
                synthetic_result = test_with_synthetic_audio(triton_client, model_name)
        
        # Print statistics
        print("\n" + "="*80)
        print("Inference Statistics")
        print("="*80)
        statistics = triton_client.get_inference_statistics(model_name=model_name)
        print(statistics)
        
        print("\n" + "="*80)
        print("ALL TESTS PASSED ‚úì")
        print("="*80)
        print("\nüìù Usage Examples:")
        print("  python test-whisper-large-v3-turbo.py")
        print("    ‚Üí Tests with LibriSpeech dataset (requires FFmpeg) or synthetic audio")
        print("\n  python test-whisper-large-v3-turbo.py /path/to/audio.wav")
        print("    ‚Üí Tests with your own audio file (WAV, MP3, FLAC, etc.)")
        print("\nüí° Tips:")
        print("  - For best results, use 16kHz mono audio files")
        print("  - Supported formats: WAV, MP3, FLAC, OGG, M4A")
        print("  - Install FFmpeg for dataset support: apt-get install ffmpeg")
        
    except Exception as e:
        print(f"\n‚úó TEST FAILED: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
